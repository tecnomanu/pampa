# ğŸ§  Proveedores de Embeddings en PAMPA

PAMPA soporta mÃºltiples proveedores de embeddings para generar vectores de cÃ³digo. Puedes elegir entre opciones locales (gratis, privadas) y APIs externas (mÃ¡s potentes).

## ğŸ  Proveedores Locales (Recomendado)

### Transformers.js

**Modelo local que ejecuta en Node.js sin dependencias externas**

```bash
# Instalar dependencia
npm install @xenova/transformers

# Indexar con modelo local
npx pampa index --provider transformers
```

**CaracterÃ­sticas:**

-   âœ… **Completamente gratis**
-   âœ… **Privacidad total** - El cÃ³digo nunca sale de tu mÃ¡quina
-   âœ… **Sin lÃ­mites de uso**
-   âœ… **Funciona offline**
-   âš ï¸ Menor calidad que modelos grandes
-   âš ï¸ Primera ejecuciÃ³n lenta (descarga modelo ~50MB)

**Modelo usado:** `all-MiniLM-L6-v2` (384 dimensiones)

### Ollama

**Modelos locales mÃ¡s potentes via Ollama**

```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Instalar modelo de embeddings
ollama pull nomic-embed-text

# Instalar dependencia Node.js
npm install ollama

# Indexar con Ollama
npx pampa index --provider ollama
```

**CaracterÃ­sticas:**

-   âœ… **Gratis y local**
-   âœ… **Modelos mÃ¡s potentes**
-   âœ… **Privacidad total**
-   âš ï¸ Requiere instalaciÃ³n de Ollama
-   âš ï¸ Usa mÃ¡s recursos (RAM/CPU)

**Modelo usado:** `nomic-embed-text` (768 dimensiones)

## ğŸŒ Proveedores de API

### OpenAI (Por defecto)

**El mÃ¡s potente y usado por defecto**

```bash
# Configurar API key
export OPENAI_API_KEY="tu-api-key"

# Indexar con OpenAI
npx pampa index --provider openai
```

**CaracterÃ­sticas:**

-   âœ… **MÃ¡xima calidad** de embeddings
-   âœ… **RÃ¡pido y confiable**
-   âœ… **Bien optimizado para cÃ³digo**
-   âŒ **Costo por uso** (~$0.0001 por funciÃ³n)
-   âŒ **Requiere internet**
-   âŒ **El cÃ³digo se envÃ­a a OpenAI**

**Modelo usado:** `text-embedding-3-large` (3072 dimensiones)
**Costo estimado:** $0.10 por 1000 funciones

### Cohere

**Alternativa mÃ¡s econÃ³mica a OpenAI**

```bash
# Instalar dependencia
npm install cohere-ai

# Configurar API key
export COHERE_API_KEY="tu-api-key"

# Indexar con Cohere
npx pampa index --provider cohere
```

**CaracterÃ­sticas:**

-   âœ… **MÃ¡s barato que OpenAI**
-   âœ… **Buena calidad**
-   âœ… **API confiable**
-   âŒ **Costo por uso** (menor que OpenAI)
-   âŒ **Requiere internet**

**Modelo usado:** `embed-english-v3.0` (1024 dimensiones)

## ğŸ”„ Auto-detecciÃ³n

Por defecto, PAMPA usa **auto-detecciÃ³n** inteligente:

```bash
# Auto-detecta el mejor proveedor disponible
npx pampa index
```

**Orden de prioridad:**

1. **OpenAI** - Si `OPENAI_API_KEY` estÃ¡ configurado
2. **Cohere** - Si `COHERE_API_KEY` estÃ¡ configurado
3. **Transformers.js** - Como fallback local

## ğŸ“Š ComparaciÃ³n de Proveedores

| Proveedor           | Costo            | Calidad      | Privacidad | Velocidad | Dimensiones |
| ------------------- | ---------------- | ------------ | ---------- | --------- | ----------- |
| **Transformers.js** | ğŸŸ¢ Gratis        | ğŸŸ¡ Buena     | ğŸŸ¢ Total   | ğŸŸ¡ Media  | 384         |
| **Ollama**          | ğŸŸ¢ Gratis        | ğŸŸ¢ Muy buena | ğŸŸ¢ Total   | ğŸŸ¡ Media  | 768         |
| **OpenAI**          | ğŸ”´ $0.0001/func  | ğŸŸ¢ Excelente | ğŸ”´ Ninguna | ğŸŸ¢ RÃ¡pida | 3072        |
| **Cohere**          | ğŸŸ¡ $0.00005/func | ğŸŸ¢ Muy buena | ğŸ”´ Ninguna | ğŸŸ¢ RÃ¡pida | 1024        |

## ğŸ› ï¸ ConfiguraciÃ³n Avanzada

### Cambiar modelo de Ollama

```javascript
// En indexer.js, puedes cambiar el modelo:
new OllamaProvider('mxbai-embed-large'); // Modelo mÃ¡s potente
```

### Usar mÃºltiples proveedores

```bash
# Indexar con diferentes proveedores para comparar
npx pampa index --provider openai
npx pampa index --provider transformers

# Buscar especificando el proveedor
npx pampa search "funciÃ³n auth" --provider openai
npx pampa search "funciÃ³n auth" --provider transformers
```

## ğŸ” Compatibilidad de BÃºsqueda

**Importante:** Solo puedes buscar en chunks indexados con el mismo proveedor y dimensiones.

```bash
# âœ… Funciona - mismo proveedor
npx pampa index --provider openai
npx pampa search "auth" --provider openai

# âŒ No encuentra resultados - diferentes proveedores
npx pampa index --provider openai
npx pampa search "auth" --provider transformers
```

## ğŸ’¡ Recomendaciones

### Para desarrollo personal/privado:

```bash
npm install @xenova/transformers
npx pampa index --provider transformers
```

### Para equipos con presupuesto:

```bash
export OPENAI_API_KEY="tu-key"
npx pampa index --provider openai
```

### Para mÃ¡ximo rendimiento local:

```bash
# Instalar Ollama primero
ollama pull nomic-embed-text
npm install ollama
npx pampa index --provider ollama
```

### Para proyectos open source:

```bash
# Usar modelo local y commitear el codemap
npx pampa index --provider transformers
git add pampa.codemap.json
git commit -m "Add PAMPA codemap with local embeddings"
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "Transformers.js no estÃ¡ instalado"

```bash
npm install @xenova/transformers
```

### Error: "Ollama no estÃ¡ instalado"

```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull nomic-embed-text
npm install ollama
```

### Error: "No se encontraron chunks indexados"

```bash
# Re-indexar con el proveedor correcto
npx pampa index --provider transformers
```

### Cambiar de proveedor

```bash
# Limpiar base de datos anterior
rm -rf .pampa/
npx pampa index --provider nuevo-proveedor
```

Â¡Elige el proveedor que mejor se adapte a tus necesidades! ğŸš€
